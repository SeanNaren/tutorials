{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/notebooks/dlsw-notebooks/riva_tts_tts-python-advanced-customization-with-ssml/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# How do I customize Riva TTS audio output with SSML?\n",
    "\n",
    "This tutorial walks you through some of the advanced features for customization of Riva TTS audio output with Speech Synthesis Markup Language (SSML)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NVIDIA Riva Overview\n",
    "\n",
    "NVIDIA Riva is a GPU-accelerated SDK for building Speech AI applications that are customized for your use case and deliver real-time performance. <br/>\n",
    "Riva offers a rich set of speech and natural language understanding services such as:\n",
    "\n",
    "- Automated speech recognition (ASR)\n",
    "- Text-to-Speech synthesis (TTS)\n",
    "- A collection of natural language processing (NLP) services, such as named entity recognition (NER), punctuation, and intent classification.\n",
    "\n",
    "In this tutorial, we will customize Riva TTS audio output with SSML. <br> \n",
    "To understand the basics of Riva TTS APIs, refer to [How do I use Riva TTS APIs with out-of-the-box models?](https://github.com/nvidia-riva/tutorials/tree/stable/tts-python-basics.ipynb). <br>\n",
    "\n",
    "For more information about Riva, refer to the [Riva developer documentation](https://developer.nvidia.com/riva)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Riva TTS audio output with SSML\n",
    "\n",
    "Speech Synthesis Markup Language (SSML) specification is a markup for directing the performance of the virtual speaker. Riva supports portions of SSML, allowing you to adjust pitch, rate, and pronunciation of the generated audio.  \n",
    "SSML support is available only for the FastPitch model at this time. The FastPitch model must be exported using NeMo>=1.5.1 and the nemo2riva>=1.8.0 tool.\n",
    "\n",
    "All SSML inputs must be a valid XML document and use the <speak> root tag. All non-valid XML and all valid XML with a different root tag are treated as raw input text.\n",
    "\n",
    "Riva TTS supports two SSML tags:  \n",
    "\n",
    "- The ``prosody`` tag, which supports two attributes ``rate`` and ``pitch``, through which we can control the rate and pitch of the generated audio.  \n",
    "\n",
    "- The ``phoneme`` tag, which allows us to control the pronunciation of the generated audio.\n",
    "\n",
    "Let's look at customization of Riva TTS with these SSML tags in some detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirements and setup\n",
    "\n",
    "1. Start the Riva Speech Skills server.  \n",
    "Follow the instructions in the [Riva Quick Start Guide](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/quick-start-guide.html#) to deploy OOTB TTS models on the Riva Speech Skills server before running this tutorial.  \n",
    "\n",
    "\n",
    "2. Install the Riva Client library.  \n",
    "Follow the steps in the [Requirements and setup for the Riva Client](https://github.com/nvidia-riva/tutorials#running-the-riva-client) to install the Riva Client library.\n",
    "\n",
    "\n",
    "3. Install the additional Python libraries to run this tutorial.  \n",
    "Run the following commands to install the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need numpy to read the output from Riva TTS request\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Riva Client Libraries\n",
    "\n",
    "Let's first import some required libraries, including the Riva Client libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import grpc\n",
    "\n",
    "import riva.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Riva Clients and connect to the Riva Speech API server\n",
    "\n",
    "The below URI assumes a local deployment of the Riva Speech API server is on the default port. In case the server deployment is on a different host or via Helm chart on Kubernetes, use an appropriate URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = riva.client.Auth(uri='localhost:50051')\n",
    "\n",
    "riva_tts = riva.client.SpeechSynthesisService(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing rate and pitch with the `prosody` tag\n",
    "\n",
    "#### Pitch Attribute\n",
    "Riva supports an additive relative change to the pitch. The `pitch` attribute has a range of [-3, 3]. Values outside this range result in an error being logged and no audio returned. This value returns a pitch shift of the attribute value multiplied with the speakerâ€™s pitch standard deviation when the FastPitch model is trained. For the pretrained checkpoint that was trained on LJSpeech, the standard deviation was 52.185. For example, a pitch shift of 1.25 results in a change of 1.25*52.185=~65.23Hz pitch shift up. \n",
    "Riva also supports the prosody tags as per the SSML specs. Prosody tags `x-low`, `low`, `medium`, `high`, `x-high`, and `default` are supported.\n",
    "\n",
    "The `pitch` attribute is expressed in the following formats:\n",
    "- `pitch=\"1\"`\n",
    "- `pitch=\"+1.8\"`\n",
    "- `pitch=\"-0.65\"`\n",
    "- `pitch=\"high\"`\n",
    "- `pitch=\"default\"`\n",
    "\n",
    "For the pretrained Female-1 checkpoint, the standard deviation is 53.33 Hz.\n",
    "For the pretrained Male-1 checkpoint, the standard deviation is 47.15 Hz.\n",
    "\n",
    "The `pitch` attribute does not support `Hz`, `st`, and `%` changes. Support is planned for a future Riva release.\n",
    "\n",
    "#### Rate Attribute\n",
    "Riva supports a percentage relative change to the rate. The `rate` attribute has a range of [25%, 250%]. Values outside this range result in an error being logged and no audio returned. \n",
    "Riva also supports the prosody tags as per the SSML specs. Prosody tags `x-low`, `low`, `medium`, `high`, `x-high`, and `default` are supported.\n",
    "\n",
    "The `rate` attribute is expressed in the following formats:\n",
    "- `rate=\"35%\"`\n",
    "- `rate=\"+200%\"`\n",
    "- `rate=\"low\"`\n",
    "- `rate=\"default\"`\n",
    "\n",
    "Let's look at an example showing these pitch and rate customizations for Riva TTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Raw text is \"Today is a sunny day. But it might rain tomorrow.\"\n",
    "    We are updating this raw text with SSML:\n",
    "    1. Envelope raw text in '<speak>' tags as is required for SSML\n",
    "    2. Add '<prosody>' tag with 'pitch' attribute set to '2.5'\n",
    "    3. Add '<prosody>' tag with 'rate' attribute set to 'high'\n",
    "\"\"\"\n",
    "raw_text = \"Today is a sunny day. But it might rain tomorrow.\"\n",
    "ssml_text = \"\"\"<speak><prosody pitch='2.5'>Today is a sunny day</prosody>. <prosody rate='high'>But it might rain tomorrow.</prosody></speak>\"\"\"\n",
    "print(\"Raw Text: \", raw_text)\n",
    "print(\"SSML Text: \", ssml_text)\n",
    "\n",
    "\n",
    "sample_rate_hz = 44100\n",
    "# Request to Riva TTS to synthesize audio\n",
    "resp = riva_tts.synthesize(\n",
    "    text=ssml_text,\n",
    "    voice_name=\"English-US.Female-1\",\n",
    "    language_code=\"en-US\",\n",
    "    encoding=riva.client.AudioEncoding.LINEAR_PCM,\n",
    "    sample_rate_hz=sample_rate_hz,\n",
    ")\n",
    "\n",
    "# Playing the generated audio from Riva TTS request\n",
    "audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "ipd.display(ipd.Audio(audio_samples, rate=sample_rate_hz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are more examples showing the effects of changes in pitch, and rate attribute values on the generated audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SSML texts we want to try\n",
    "ssml_texts = [\n",
    "  \"\"\"<speak>This is a normal sentence</speak>\"\"\",\n",
    "  \"\"\"<speak><prosody pitch=\"0.\" rate=\"100%\">This is also a normal sentence</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak><prosody rate=\"200%\">This is a fast sentence</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak><prosody rate=\"60%\">This is a slow sentence</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak><prosody pitch=\"+1.0\">Now, I'm speaking a bit higher</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak><prosody pitch=\"-0.5\">And now, I'm speaking a bit lower</prosody></speak>\"\"\",\n",
    "  \"\"\"<speak>S S M L supports <prosody pitch=\"-1\">nested tags. So I can speak <prosody rate=\"150%\">faster</prosody>, <prosody rate=\"75%\">or slower</prosody>, as desired.</prosody></speak>\"\"\",\n",
    "]\n",
    "\n",
    "sample_rate_hz = 44100\n",
    "# Loop through 'ssml_texts' list and synthesize audio with Riva TTS for each entry 'ssml_texts'\n",
    "for ssml_text in ssml_texts:\n",
    "    resp = riva_tts.synthesize(\n",
    "        text=ssml_text,\n",
    "        voice_name=\"English-US.Female-1\",\n",
    "        language_code=\"en-US\",\n",
    "        encoding=riva.client.AudioEncoding.LINEAR_PCM,\n",
    "        sample_rate_hz=sample_rate_hz,\n",
    "    )\n",
    "    audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "    print(\"SSML Text: \", ssml_text)\n",
    "    ipd.display(ipd.Audio(audio_samples, rate=sample_rate_hz))\n",
    "    print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing pronunciation with the `phenome` tag\n",
    "\n",
    "We can use the `phoneme` tag to override the pronunciation of words from the predicted pronunciation. For a given word or sequence of words, use the `ph` attribute to provide an explicit pronunciation, and the `alphabet` attribute to provide the phone set.  \n",
    "Currently, only `x-arpabet` is supported for pronunciation dictionaries based on CMUdict. IPA support will be added soon.\n",
    "\n",
    "The full list of phonemes in the CMUdict can be found at [cmudict.phone](https://github.com/cmusphinx/cmudict/blob/master/cmudict.phones). The list of supported symbols with stress can be found at [cmudict.symbols](https://github.com/cmusphinx/cmudict/blob/master/cmudict.symbols). For a mapping of these phones to English sounds, refer to the [ARPABET Wikipedia page](https://en.wikipedia.org/wiki/ARPABET).\n",
    "\n",
    "Let's look at an example showing this custom pronunciation for Riva TTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Riva TTS request with SynthesizeSpeechRequest\n",
    "\"\"\"\n",
    "    Raw text is \"You say tomato, I say tomato.\"\n",
    "    We are updating this raw text with SSML:\n",
    "    1. Envelope raw text in '<speak>' tags as is required for SSML\n",
    "    2. For a substring in the raw text, add '<phoneme>' tags with 'alphabet' attribute set to 'x-arpabet' \n",
    "       (currently the only supported value) and 'ph' attribute set to a custom pronunciation based on CMUdict and ARPABET\n",
    "\n",
    "\"\"\"\n",
    "raw_text = \"You say tomato, I say tomato.\"\n",
    "ssml_text = '<speak>You say <phoneme alphabet=\"x-arpabet\" ph=\"{@T}{@AH0}{@M}{@EY1}{@T}{@OW2}\">tomato</phoneme>, I say <phoneme alphabet=\"x-arpabet\" ph=\"{@T}{@AH0}{@M}{@AA1}{@T}{@OW2}\">tomato</phoneme>.</speak>'\n",
    "\n",
    "print(\"Raw Text: \", raw_text)\n",
    "print(\"SSML Text: \", ssml_text)\n",
    "\n",
    "sample_rate_hz = 44100\n",
    "# Request to Riva TTS to synthesize audio\n",
    "resp = riva_tts.synthesize(\n",
    "    text=ssml_text,\n",
    "    voice_name=\"English-US.Female-1\",\n",
    "    language_code=\"en-US\",\n",
    "    encoding=riva.client.AudioEncoding.LINEAR_PCM,\n",
    "    sample_rate_hz=sample_rate_hz,\n",
    ")\n",
    "\n",
    "# Playing the generated audio from Riva TTS request\n",
    "audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "ipd.display(ipd.Audio(audio_samples, rate=sample_rate_hz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are more examples showing the customization of pronunciation in generated audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSML texts we want to try\n",
    "ssml_texts = [\n",
    "  \"\"\"<speak>Is it <phoneme alphabet=\"x-arpabet\" ph=\"{@S}{@K}{@EH1}{@JH}{@UH0}{@L}\">schedule</phoneme> or <phoneme alphabet=\"x-arpabet\" ph=\"{@SH}{@EH1}{@JH}{@UW0}{@L}\">schedule</phoneme>?</speak>\"\"\",\n",
    "  \"\"\"<speak>You say <phoneme alphabet=\"x-arpabet\" ph=\"{@D}{@EY1}{@T}{@AH0}\">data</phoneme>, I say <phoneme alphabet=\"x-arpabet\" ph=\"{@D}{@AE1}{@T}{@AH0}\">data</phoneme>.</speak>\"\"\",\n",
    "  \"\"\"<speak>Some people say <phoneme alphabet=\"x-arpabet\" ph=\"{@R}{@UW1}{@T}\">route</phoneme> and some say <phoneme alphabet=\"x-arpabet\" ph=\"{@R}{@AW1}{@T}\">route</phoneme>.</speak>\"\"\",\n",
    "]\n",
    "\n",
    "# Loop through 'ssml_texts' list and synthesize audio with Riva TTS for each entry 'ssml_texts'\n",
    "sample_rate_hz = 44100\n",
    "for ssml_text in ssml_texts:\n",
    "    resp = riva_tts.synthesize(\n",
    "        text=ssml_text,\n",
    "        voice_name=\"English-US.Female-1\",\n",
    "        language_code=\"en-US\",\n",
    "        encoding=riva.client.AudioEncoding.LINEAR_PCM,\n",
    "        sample_rate_hz=sample_rate_hz,\n",
    "    )\n",
    "    audio_samples = np.frombuffer(resp.audio, dtype=np.int16)\n",
    "    print(\"SSML Text: \", ssml_text)\n",
    "    ipd.display(ipd.Audio(audio_samples, rate=sample_rate_hz))\n",
    "    print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about customizing Riva TTS with SSML can also be found in the documentation [here](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/tts/tts-ssml.html#). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go deeper into Riva capabilities\n",
    "\n",
    "### Additional Riva tutorials\n",
    "\n",
    "Checkout more Riva TTS (and ASR) tutorials [here](https://github.com/nvidia-riva/tutorials). These tutorials provide a deeper understanding of the advanced features of Riva TTS, including customizing TTS for your specific needs.\n",
    "\n",
    "### Sample applications\n",
    "\n",
    "Riva comes with various sample applications. They demonstrate how to use the APIs to build applications such as a [chatbot](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/samples/weather.html), a domain specific speech recognition, [keyword (entity) recognition system](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/samples/callcenter.html), or simply how Riva allows scaling out for handling massive amounts of requests at the same time. Refer to ([SpeechSquad)](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/samples/speechsquad.html) for more information.  \n",
    "Refer to the *Sample Application* section in the [Riva developer documentation](https://developer.nvidia.com/) for more information.\n",
    "\n",
    "\n",
    "###  Riva Automated Speech Recognition (ASR)\n",
    "\n",
    "Riva's ASR offering comes with OOTB pipelines for English, German, Spanish, Russian and Mandarin. It can be used in streaming or batch inference modes and easily deployed using the [Riva Quick Start scripts](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/quick-start-guide.html). Follow [this link](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/asr/asr-overview.html) to better understand Riva's ASR capabilities. Explore how to use Riva ASR APIs with the OOTB voices with [this Riva ASR tutorial](https://github.com/nvidia-riva/tutorials/blob/dev/22.04/asr-python-basics.ipynb).\n",
    "\n",
    "\n",
    "### Additional resources\n",
    "\n",
    "For more information about each of the APIs and their functionalities, refer to the [documentation](https://docs.nvidia.com/deeplearning/riva/user-guide/docs/protobuf-api/protobuf-api-root.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
